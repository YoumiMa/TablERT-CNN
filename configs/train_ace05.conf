[1]
label = ace05
model_type = tablert_cnn
model_path = bert-base-cased
tokenizer_path = bert-base-cased
train_path = data/datasets/ace05/ace05_train.json
valid_path = data/datasets/ace05/ace05_test.json
types_path = data/datasets/ace05/ace05_types.json
train_batch_size = 8
eval_batch_size = 8
epochs = 30
lr = 1e-3
lr_bert = 5e-5
lr_warmup = 0.2
scheduler = cosine_warmup
weight_decay = 0.01
max_grad_norm = 1.0
encoder_hidden = 512
kernel_size = 5
conv_layers = 2
prop_drop = 0.3
bert_layer = 12
freeze_transformer = false
store_examples = true
final_eval = true
log_path = data/log/
save_path = data/save/
sampling_processes = 0
