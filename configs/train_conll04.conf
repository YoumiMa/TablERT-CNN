[1]
label = conll04
model_type = tablert_cnn
model_path = bert-base-cased
tokenizer_path = bert-base-cased
train_path = data/datasets/conll04_check/conll04_train_dev.json
valid_path = data/datasets/conll04_check/conll04_test.json
types_path = data/datasets/conll04/conll04_types.json
train_batch_size = 8
eval_batch_size = 8
epochs = 30
lr = 1e-3
lr_bert = 5e-5
lr_warmup = 0.2
scheduler = cosine_warmup
weight_decay = 0.01
max_grad_norm = 1.0
encoder_hidden = 512
kernel_size = 3
conv_layers = 2
bert_layer = 12
prop_drop = 0.3
store_examples = true
final_eval = true
log_path = data/log/
save_path = data/save/
freeze_transformer = false
sampling_processes = 0